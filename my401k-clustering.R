#
# @rob4lderman
# feb 2017
#
# My401k fund analysis
# Clustering functions
#
#
# Evaluation of cluster validity measures:
# https://pdfs.semanticscholar.org/c4f9/df3c66105382d05e58ec35faa8d435f55c91.pdf
# http://datamining.rutgers.edu/publication/internalmeasures.pdf
#
#
# TODO: use data frames instead of matrices (R will pass data frames by-ref if
#       they're not modified)
#

library(clv)        # cluster validation techniques


My401kClustering <- list()


#
# The Hartigan rule of thumb for choosing number of clusters states that another cluster
# should be added (k+1) if the following is true:
# 
#     k: the result with k clusters
#     k+1: the result with k+1 clusters
#     n: size of data set (num rows)
#     ESS: within sum-of-squares
#     
#     (  SUM_i=1..k ESS      )
#     ( ---------------- - 1 ) * (n - k - 1) > 10
#     ( SUM_i=1..k+1 ESS     )
# 
#        (this term is            (this term
#         basically the            gets smaller
#         "return" on adding       as k increases)
#         a new cluster)
# 
# @param km1 kmeans results using k clusters
# @param km2 kmeans results using k+1 clusters
#
# @return the hartigan score between the two clustering results
# 
My401kClustering$hartiganScore <- function(km1, km2) {
        
    n <- sum(km1$size)           # total # of data points
    k <- length(km1$size)       
    (km1$tot.withinss / km2$tot.withinss - 1) * (n - k - 1)
}


#
#
# @param data.mat - the data matrix to cluster
# @param num.clusters.vec - vector of number-of-clusters to use 
#
# @return a list of kmeans() clustering results, one for each num.clusters
#         in num.clusters.vec
# 
My401kClustering$generateKmeansResults <- function(data.mat, 
                                                   num.clusters.vec) {

    set.seed(1234)
    lapply( num.clusters.vec, 
                       function(num.clusters) { 
                           kmeans(data.mat,
                                  centers=num.clusters,
                                  nstart=20, 
                                  iter.max=20 )
                       } )
}


#
# List funds for each cluster
#
# km$cluster identifies the cluster assigned to each row/rowname/record 
# from the original dataset (i.e the ticker symbol)
#
# @return a list of vectors of ticker symbols, one vector for each cluster
#
My401kClustering$getClusterTickersList <- function(km) {
    num.clusters <- length(km$size)
    lapply( 1:num.clusters, 
            function(cluster.idx) { 
                names(km$cluster)[ km$cluster == cluster.idx ] 
            })
}


#
#
# @return a list of data frames containing fund data for each cluster
#
My401kClustering$getClusterFundsList <- function(cluster.tickers.list, funds.df) {

    lapply(cluster.tickers.list, 
           function(cluster.tickers) {
               funds.df %>% 
                   filter(ticker %in% cluster.tickers) %>% 
                   mutate(ticker = as.character(ticker))   # for subset'ing on rowname
           })
}


#
# @return the number of clusters in the given kmeans result
#
My401kClustering$getNumClusters <- function(km) {
    length(km$size)
}


#
# @return a vector containing the number of clusters in each kmeans result
#
My401kClustering$pluckNumClusters <- function(km.list) {
    sapply(km.list, function(km) { length(km$size) } )
}


#
#
# Evaluates kmeans results using various measures including:
#   - Hartigan score
#   - R^2 (% variance explained  =  1 - withinSS / totalSS  =  betweenSS / totalSS)
#   - S_Dbw
#
# 
# @param km.list - list of kmeans results with different numbers-of-clusters
#                  (as generated by generateKmeansResults)
#               
# @return list(hartigan.scores=[..], 
#              r.squared=[..],
#              s.dbw=[..])
# 
My401kClustering$evaluateKmeansResults <- function(km.list, data.mat) {

    list(  num.clusters = My401kClustering$pluckNumClusters(km.list),
         hartigan.score = My401kClustering$computeHartiganScores(km.list),
              r.squared = My401kClustering$computeRSquareds(km.list),
                  s.dbw = My401kClustering$computeSDbwIndexes(km.list, data.mat),
                     sd = My401kClustering$computeSDIndexes(km.list, data.mat),
                     db = My401kClustering$computeDBIndexes(km.list, data.mat) )
}

    
#
# Compute hartigan scores for the given kmeans results
#
# @param km.list - list of kmeans results with different numbers-of-clusters
#                  (as generated by generateKmeansResults)
#
# @return a vector of hartigan scores
#
My401kClustering$computeHartiganScores <- function(km.list) {

    hartigan.scores <- rep(0, length(km.list))

    for (i in 1:(length(km.list)-1)) {
        hartigan.scores[i] <- My401kClustering$hartiganScore(km.list[[i]], km.list[[i+1]])
    }

    hartigan.scores
}


#
#
#   R^2  =  % variance explained  =  1 - withinSS / totalSS  =  betweenSS / totalSS)
#
# Larger == Better
#
# @return scalar R^2 for the given kmeans result 
#
My401kClustering$computeRSquared <- function(km) {

    km$betweenss / km$totss
}


#
#
# @param km.list - list of kmeans results with different numbers-of-clusters
#                  (as generated by generateKmeansResults)
#
# @return a vector of R-squared's for each kmeans result
#
My401kClustering$computeRSquareds <- function(km.list) {

    sapply(km.list, My401kClustering$computeRSquared )
}


#
# Evaluation of cluster validity measures:
# https://pdfs.semanticscholar.org/c4f9/df3c66105382d05e58ec35faa8d435f55c91.pdf
# http://datamining.rutgers.edu/publication/internalmeasures.pdf
#
# SD takes into account avg scattering of clusters and the separation between clusters
#
# SD = scatt * alfa + dis
#
# Lower == Better
#
# Has difficulty with sub-clusters
#
# @return scalar SD index for the given kmeans clustering result
#
My401kClustering$computeSDIndex <- function(km, data.mat) {

    scatt <- clv.Scatt(data.mat, km$cluster)
    dis <- clv.Dis(km$centers)
    num.clusters <- length(km$size)

    clv.SD(scatt$Scatt, dis, alfa=num.clusters)
}


#
# @return a vector of SD indexes for the given kmeans results
#
My401kClustering$computeSDIndexes <- function(km.list, data.mat) {

    sapply(km.list, 
           function(km) { 
               My401kClustering$computeSDIndex(km, data.mat) 
           } )
}


#
# DB: avg {max similarity} between each cluster and all others
#
# Lower == Better (low similarity between clusters)
#
# Has difficulty with sub-clusters
#
# @param intraclust = c("complete","average","centroid")
# @param interclust = c("single", "complete", "average","centroid", "aveToCent", "hausdorff")
#
# @return matrix of DB index values for the given kmeans clustering result
#
My401kClustering$computeDBIndex <- function(km, 
                                            data.mat, 
                                            intraclust = c("centroid"),
                                            interclust = c("centroid")) {

    scatt <- cls.scatt.data(data.mat, km$cluster)

    retme.mat <- clv.Davies.Bouldin(scatt, intraclust, interclust)

    ifelse(length(retme.mat) == 1, retme.mat[1,1], retme.mat)
}


#
# @return a vector of DB indexes for the given kmeans results
#
My401kClustering$computeDBIndexes <- function(km.list, data.mat) {

    sapply(km.list, 
           function(km) { 
               My401kClustering$computeDBIndex(km, data.mat) 
           } )
}


#
#
# Lower == Better
#
# @return scalar S_Dbw index for the given kmeans clustering result
#
My401kClustering$computeSDbwIndex <- function(km, data.mat) {

    scatt <- clv.Scatt(data.mat, km$cluster)

    #
    # Note: clv.DensBw always returning Inf.
    #       I think it's due to the high-dimensionality of the data.
    #       The density of a cluster is computed by counting the # of
    #       data points in a hyper-sphere with radius = avg cluster stdev.
    #       Since the data has high dimensionality, the volume of the space
    #       blows up exponentially and the data points become much more
    #       spread out, resulting in cluster densities of 0, which ends up in 
    #       the denominator and causes clv.DensBw to return Inf.
    #       
    dens.bw <- clv.DensBw(data.mat, km$cluster, scatt)
    clv.SDbw(scatt$Scatt, dens.bw)
}



#
# @return a vector of S_Dbw indexes for the given kmeans results
#
My401kClustering$computeSDbwIndexes <- function(km.list, data.mat) {

    sapply(km.list, 
           function(km) { 
               My401kClustering$computeSDbwIndex(km, data.mat) 
           } )
}



